[["index.html", "Arrow Cookbook 1 Preface", " Arrow Cookbook 1 Preface This cookbook aims to provide a number of recipes showing how to perform common tasks using arrow. "],["reading-and-writing-data.html", "2 Reading and Writing Data 2.1 Reading and Writing Parquet Files 2.2 How to read a (partitioned) Parquet file from S3 2.3 How to filter rows or columns while reading a Parquet file 2.4 Reading and Writing CSV files 2.5 Reading and Writing Partitioned Data 2.6 Reading and Writing Feather files 2.7 Reading and Writing Streaming IPC Files", " 2 Reading and Writing Data This chapter contains recipes related to reading and writing data from disk using Apache Arrow. 2.1 Reading and Writing Parquet Files 2.1.1 Writing a Parquet file You can write Parquet files to disk using arrow::write_parquet(). # Create table my_table &lt;- Table$create(tibble::tibble(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99))) # Write to Parquet write_parquet(my_table, &quot;my_table.parquet&quot;) 2.1.2 Reading a Parquet file Given a Parquet file, it can be read back to an Arrow Table by using arrow::read_parquet(). parquet_tbl &lt;- read_parquet(&quot;my_table.parquet&quot;) head(parquet_tbl) ## # A tibble: 3 x 2 ## group score ## &lt;chr&gt; &lt;dbl&gt; ## 1 A 99 ## 2 B 97 ## 3 C 99 If the argument as_data_frame was set to TRUE (the default), the file was read in as a data.frame object. class(parquet_tbl) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; If you set as_data_frame to FALSE, the file will be read in as an Arrow Table. my_table_arrow_table &lt;- read_parquet(&quot;my_table.parquet&quot;, as_data_frame = FALSE) head(my_table_arrow_table) ## Table ## 3 rows x 2 columns ## $group &lt;string&gt; ## $score &lt;double&gt; class(my_table_arrow_table) ## [1] &quot;Table&quot; &quot;ArrowTabular&quot; &quot;ArrowObject&quot; &quot;R6&quot; 2.2 How to read a (partitioned) Parquet file from S3 You can open a Parquet file saved on S3 by calling read_parquet() and passing the relevant URI as the file argument. df &lt;- read_parquet(file = &quot;s3://ursa-labs-taxi-data/2019/06/data.parquet&quot;) For more in-depth instructions, including how to work with S3 buckets which require authentication, you can find a guide to reading and writing to/from S3 buckets here: https://arrow.apache.org/docs/r/articles/fs.html. 2.3 How to filter rows or columns while reading a Parquet file When reading in a Parquet file, you can specify which columns to read in via the col_select argument. # Create table to read back in dist_time &lt;- Table$create(tibble::tibble(distance = c(12.2, 15.7, 14.2), time = c(43, 44, 40))) # Write to Parquet write_parquet(dist_time, &quot;dist_time.parquet&quot;) # Read in only the &quot;time&quot; column time_only &lt;- read_parquet(&quot;dist_time.parquet&quot;, col_select = &quot;time&quot;) head(time_only) ## # A tibble: 3 x 1 ## time ## &lt;dbl&gt; ## 1 43 ## 2 44 ## 3 40 2.4 Reading and Writing CSV files You can use write_csv_arrow() to save an Arrow Table to disk as a CSV. write_csv_arrow(cars, &quot;cars.csv&quot;) You can use read_csv_arrow() to read in a CSV file as an Arrow Table. my_csv &lt;- read_csv_arrow(&quot;cars.csv&quot;) 2.5 Reading and Writing Partitioned Data 2.5.1 Writing Partitioned Data You can use write_dataset() to save data to disk in partitions based on columns in the data. write_dataset(airquality, &quot;airquality_partitioned&quot;, partitioning = c(&quot;Month&quot;, &quot;Day&quot;)) list.files(&quot;airquality_partitioned&quot;) ## [1] &quot;Month=5&quot; &quot;Month=6&quot; &quot;Month=7&quot; &quot;Month=8&quot; &quot;Month=9&quot; As you can see, this has created folders based on the first partition variable supplied, Month. If you take a look in one of these folders, you will see that the data is then partitioned by the second partition variable, Day. list.files(&quot;airquality_partitioned/Month=5&quot;) ## [1] &quot;Day=1&quot; &quot;Day=10&quot; &quot;Day=11&quot; &quot;Day=12&quot; &quot;Day=13&quot; &quot;Day=14&quot; &quot;Day=15&quot; &quot;Day=16&quot; ## [9] &quot;Day=17&quot; &quot;Day=18&quot; &quot;Day=19&quot; &quot;Day=2&quot; &quot;Day=20&quot; &quot;Day=21&quot; &quot;Day=22&quot; &quot;Day=23&quot; ## [17] &quot;Day=24&quot; &quot;Day=25&quot; &quot;Day=26&quot; &quot;Day=27&quot; &quot;Day=28&quot; &quot;Day=29&quot; &quot;Day=3&quot; &quot;Day=30&quot; ## [25] &quot;Day=31&quot; &quot;Day=4&quot; &quot;Day=5&quot; &quot;Day=6&quot; &quot;Day=7&quot; &quot;Day=8&quot; &quot;Day=9&quot; Each of these folders contains 1 or more Parquet files containing the relevant partition of the data. list.files(&quot;airquality_partitioned/Month=5/Day=10&quot;) ## [1] &quot;part-9.parquet&quot; 2.5.2 Reading Partitioned Data You can use open_dataset() to read partitioned data. # Write some partitioned data to disk to read back in write_dataset(airquality, &quot;airquality_partitioned&quot;, partitioning = c(&quot;Month&quot;, &quot;Day&quot;)) # Read data from directory air_data &lt;- open_dataset(&quot;airquality_partitioned&quot;) # View data air_data ## FileSystemDataset with 153 Parquet files ## Ozone: int32 ## Solar.R: int32 ## Wind: double ## Temp: int32 ## Month: int32 ## Day: int32 ## ## See $metadata for additional Schema metadata 2.6 Reading and Writing Feather files 2.6.1 Write an IPC/Feather V2 file The Arrow IPC file format is identical to the Feather version 2 format. If you call write_arrow(), you will get a warning telling you to use write_feather() instead. # Create table my_table &lt;- Table$create(tibble::tibble(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99))) write_arrow(my_table, &quot;my_table.arrow&quot;) ## Warning: Use &#39;write_ipc_stream&#39; or &#39;write_feather&#39; instead. Instead, you can use write_feather(). my_table &lt;- Table$create(tibble::tibble(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99))) write_feather(my_table, &quot;my_table.arrow&quot;) 2.6.2 Write a Feather (version 1) file You can write data in the original Feather format by setting the version parameter to 1. # Create table my_table &lt;- Table$create(tibble::tibble(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99))) # Write to Feather format V1 write_feather(mtcars, &quot;my_table.feather&quot;, version = 1) 2.6.3 Read a Feather file You can read Feather files in via read_feather(). my_feather_tbl &lt;- read_feather(&quot;my_table.arrow&quot;) 2.7 Reading and Writing Streaming IPC Files You can write to the IPC stream format using write_ipc_stream(). # Create table my_table &lt;- Table$create(tibble::tibble(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99))) # Write to IPC stream format write_ipc_stream(my_table, &quot;my_table.arrows&quot;) You can read from IPC stream format using read_ipc_stream(). my_ipc_stream &lt;- arrow::read_ipc_stream(&quot;my_table.arrows&quot;) "],["creating-arrow-objects.html", "3 Creating Arrow Objects 3.1 Build an Arrow Table from native language types 3.2 Storing Categorical Data in Arrow", " 3 Creating Arrow Objects 3.1 Build an Arrow Table from native language types 3.1.1 Manually create a table from an R object You may want to convert an existing data frame in R to an Arrow Table object. # Create an example data frame my_tibble &lt;- tibble::tibble(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99)) # Convert to Arrow Table my_table &lt;- Table$create(my_tibble) # View table my_table ## Table ## 3 rows x 2 columns ## $group &lt;string&gt; ## $score &lt;double&gt; 3.1.1.1 View the contents of an Arrow Table You can view the contents of an Arrow table using dplyr::collect() # View Table dplyr::collect(my_table) ## # A tibble: 3 x 2 ## group score ## &lt;chr&gt; &lt;dbl&gt; ## 1 A 99 ## 2 B 97 ## 3 C 99 3.1.2 Manually create a RecordBatch You may want to convert an existing data frame in R to an Arrow Record Batch object. # Create an example data frame my_tibble &lt;- tibble::tibble(group = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), score = c(99, 97, 99)) # Convert to Arrow RecordBatch my_record_batch &lt;- record_batch(my_tibble) # View RecordBatch my_record_batch ## RecordBatch ## 3 rows x 2 columns ## $group &lt;string&gt; ## $score &lt;double&gt; 3.1.2.1 View the contents of a RecordBatch You can view the contents of a RecordBatch using dplyr::collect() # View RecordBatch dplyr::collect(my_record_batch) ## # A tibble: 3 x 2 ## group score ## &lt;chr&gt; &lt;dbl&gt; ## 1 A 99 ## 2 B 97 ## 3 C 99 3.2 Storing Categorical Data in Arrow An Arrow Dictionary object is similar to a factor in R, in that it allows for efficient storage of categorical data by allowing you to map between indices and values, reducing the amount of storage. If you have an R data frame containing factors, converting it to an Arrow object will automatically encode that column as a dictionary. class(iris$Species) ## [1] &quot;factor&quot; iris_rb &lt;- record_batch(iris) iris_rb ## RecordBatch ## 150 rows x 5 columns ## $Sepal.Length &lt;double&gt; ## $Sepal.Width &lt;double&gt; ## $Petal.Length &lt;double&gt; ## $Petal.Width &lt;double&gt; ## $Species &lt;dictionary&lt;values=string, indices=int8&gt;&gt; ## ## See $metadata for additional Schema metadata "],["manipulating-data.html", "4 Manipulating Data 4.1 Computing Mean/Min/Max, etc value of an array 4.2 Counting occurrences of elements in an array 4.3 Applying arithmetic functions to arrays.", " 4 Manipulating Data 4.1 Computing Mean/Min/Max, etc value of an array Many base R functions such as mean(), min(), and max() have been mapped to their Arrow equivalents, and so can be called on Arrow Array objects in the same way. They will return Arrow object themselves. my_values &lt;- Array$create(c(1:5, NA)) mean(my_values, na.rm = TRUE) ## Scalar ## 3 If you want to use an R function which does not have an Arrow mapping, you can use as.vector() to convert Arrow objects to base R vectors. fivenum(as.vector(my_values)) ## [1] 1 2 3 4 5 4.2 Counting occurrences of elements in an array You can use value_count() to count elements in an Array. repeated_vals &lt;- Array$create(c(1, 1, 2, 3, 3, 3, 3, 3)) value_counts(repeated_vals) ## StructArray ## &lt;struct&lt;values: double, counts: int64&gt;&gt; ## -- is_valid: all not null ## -- child 0 type: double ## [ ## 1, ## 2, ## 3 ## ] ## -- child 1 type: int64 ## [ ## 2, ## 1, ## 5 ## ] 4.3 Applying arithmetic functions to arrays. You can use the various arithmetic operators on Array objects. num_array &lt;- Array$create(1:10) num_array + 10 ## Array ## &lt;double&gt; ## [ ## 11, ## 12, ## 13, ## 14, ## 15, ## 16, ## 17, ## 18, ## 19, ## 20 ## ] You’ll get the same result if you pass in the value you’re adding as an Arrow object. num_array + Scalar$create(10) ## Array ## &lt;double&gt; ## [ ## 11, ## 12, ## 13, ## 14, ## 15, ## 16, ## 17, ## 18, ## 19, ## 20 ## ] "]]
